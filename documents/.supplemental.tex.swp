\documentclass[paper.tex]{subfiles}
\begin{document}


\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
{\Large Captain's Log, Supplemental}\\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Molecular dynamics simulation}
\
%\begin{multicols}{1}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

It was originally expected that a large part of this work would be done in-silico, as we did not anticipate having access to suitable RF test equipment. 

Some time was spent attempting to set up a molecular dynamics toolchain capable of simulating an entire virus. 

Having an approximate simulation of the this technique would be useful for a number of reasons: 

We would have a better idea of the transferability to SARS, without wasting the time of experts with BSL-3/4 labs.

The impulse could be subjected to the same optimization as the RF feedback loop. A number of parameters (such as phase, polarization)



Coarse-graining also greatly increases the allowable timestep.


%\end{multicols}




\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
{\Large Optical centrifuge polarization chirp}\\
\begin{multicols}{1}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\includepdf[
    %% Include all pages of the PDF
    pages=-,
    %% make this page have the usual page style
    %% (you can change it to plain etc). By default pdfpages
    %% sets the pagecommand to \pagestyle{empty}
    pagecommand={\pagestyle{headings}},  
    %% Add a "section" entry to the ToC with the heading
    %% "Quilling Shapes" and the label "sec:shapes"
    addtotoc={1,section,1,Quilling Shapes,sec:shapes}]
%% The pdf file itself
{optical_centrifuge.pdf}


\end{multicols}




\clearpage
\rule{\linewidth}{0.2pt}

There seems to be a discrepancy between [Yang 2015] and our reading of [C95.1-2005].

They use a threshold in open public space of $100(f/3)^{1/5} \text{ W/m}^2$. The 115 W @ 6 GHz they provide correctly corresponds to this equation with a coefficient of 100.

For Table 9, general public, the equation is $18.56 (f)^{0.699} \text{ W/m}^2$, or $64.93 \text{ W}/\text{m}^2$ @ 6 GHz. 

Different versions of the IEEE standard have used equations of equivalent form but with different coefficients [Wu 2015]; it is very possible that we have retrieved the wrong standard.

\rule{\linewidth}{0.2pt}

CEL did not supply a SPICE model for the GaAs FET device used in early prototypes. A FET was originally because a gate is ostensibly easier to bias than a base; but this turned out to be unfounded.

[Steenput 1999] has an interesting analytic method to synthesize a SPICE model suitable for a transient simulations from S-parameter measurements using negative resistances. However, this neglects the I/V characteristic. 

[Polyfet 1998] describes a simple optimization method to synthesize a SPICE model for an active device, and CEL appnote provides some details for GaAs devices.



\rule{\linewidth}{0.2pt}

OpenEMS is excellent, with Python bindings, some lumped components, and mesh refinement. However, embarassingly, we were not able to resolve all the dependency issues in order to install it.

\rule{\linewidth}{0.2pt}

The oscillator design is a testament  This highlights that a computation is not a substitute for understanding.


We began experimentally by building a scaled version of [Mueller 2008]'s active antenna crudely with copper tape, using a CEL [] FET.



We then manually tried a number of filter designs, using the manufacturer's S-parameters and QUCS' microstrip approximations. This intially appeared to yield good agreement with experiment. Peaks in the feedback voltage simulation corresponded approximately with peaks in the observed spectrum. [figures from LO prototype N]. 

A crude, inane, and extremely disorganized trial-and-error procedure was performed for many weeks. A wide variety of analytical methods for filter design were attempted, but simultaneously obtaining the correct phase shift and frequency response was somewhat difficult. The parasitic inductance of the varactors always seemed to destroy our most perfect creations.

An SIR filter has the added advantage of confusing epidemiologists greatly.

Eventually, QUCS, zonca/python-qucs, and scipy's basinhopper was used with the cost function somewhat similar to that described in [Kaplevich]:

\begin{verbatim}
    freq_coeff = 1
    phase_coeff = 1.5
    ratio_coeff = 0.5
    insertion_loss_coeff = 0.2
 
    frequency_cost = freq_coeff * (abs(desired_center_frequency-fb_peak_frequencies[0])/1e9)
    phase_cost = phase_coeff * abs(1.0 - phase_at_peak)
    ratio_cost = ratio_coeff * fb_peak_ratio
    insertion_loss_cost = insertion_loss_coeff*(1.0 - fb_peak_values[0])
    cost = frequency_cost + phase_cost + fb_peak_ratio + insertion_loss_cost
\end{verbatim}

Optimizing first for the high frequency, fixing the inductor and microstrip values, and then optimizing for the varactor values at the low frequency.

This produced a seemingly acceptable feedback loop:

\includegraphics[scale=1]{LO_2_pole_test.png}

However, when this was built, varactor tuning performance was abysmal, with hops and peaks; and the tuning range was far smaller than expected.

It was thought that a transient simulation - to determine how the spectrum actually evolved - would improve the situation. 

As of 0.0.20, QUCS' microstrip models are not yet compatible with transient simulations; and some improved filter designs required simulating coupling between more than two microstrips, which QUCS did not yet support natively.

\includegraphics[scale=0.5]{3d_spectrum_2.png}

The complete transient simulation matched reality very closely. 




Because we lacked a spectrum analyzer that could monitor the higher poles of the filter until the bootstrap LO was designed, we had to rely on in-silico analyeses.


Transient simulations with ngspice matched experiment far more closely.

\rule{\linewidth}{0.2pt}

Again, inductive choke biasing in the feedback loop was practically impossible. Biasing PiN diodes with a 10kohm resistor, (with 330 ohm safety resistor) one to 48V bias and another through an 2N7002P N-channel mosfet worked fine. 

The oscillator ran fine with a PiN bias of 2.34 mA. [LO prototype N]. A high bias voltage of 48V was required to get sufficient current through the two 10K resistors and the PiN diode to obtain a low impedance while remaining delicate with the vfb.

The PiN diode used has a resting resistance of 500 ohms, 5 ohms at 2 mA and 2 ohms at ??. 

48V is a little tight on the 50V rated voltage of our DC blocking capacitors.

Each activated PiN diode should be biased separately, since putting 2x 2 mA through 20K would take an impractical 80V.

\rule{\linewidth}{0.2pt}

Conductors are represented by zeroing all components of the electric field in those regions. 

There are many different possible source geometries, each introducing their own distortions.

There are many ways of linking SPICE and FDTD. 

\rule{\linewidth}{0.2pt}

Bandpass filters can be designed by first designing a low-pass filter prototype (usually Chebychev) (or, in our case, using reference filter component tables), and then transforming this low-pass into a band-pass. [Hunter 2001] is an excellent overview of this process, with many design examples for different filter topologies. 

The coupling coefficient between two low-pass filters determines the band-pass bandwidth.[Hui 2012]

[Hunter 2001] also describes an analytical method to create a filter with the precise group delay - phase shift versus frequency - required for stable oscillation. However, simultaneously compensating for the group delay introduced by the amplifier itself (nearly 180 degrees over the frequency range for the CEL part) seemed complex.

Phase shift can be introduced either via a length of microstrip, or a high-pass/low-pass filter [Microwave101]. Adding a fixed microstrip line restricts the tuning range, however, and the filter inevitably affects the frequency response.  

\rule{\linewidth}{0.2pt}

NGSPICE's KSPICE coupled transmission lines require the capacitance and inductance per unit length in Maxwell matrix form, rather than the physical $C_{even}$/$L_{even}$ (each line's capacitance and inductance to ground) and $_{odd}$ (between elements) form provided by tools like wcalc. "matrix not positive definite". [Schutt-Aine] discusses this; we reproduce here for convienience.

\[ L_{11} = L_{22} = L_{even}  \]
\[ L_{12} = L_{21} = L_{odd}  \]
\[ C_{11} = C_{22} = C_{even}+C_{odd}  \]
\[ C_{12} = C_{21} {\it{(unused)}} = -C_{odd}  \]

\rule{\linewidth}{0.2pt}

In practice, the timestep required to obtain convergence in particularly tight corners of the SPICE simulation can drop to 1e-20, which is far below the Courant limit of the FDTD simulation. To eek out a bit more performance, a simple adaptive-timestep technique from [ a ] is used; we simply set the timestep so that the maximum change in voltage per timestep from the non-FDTD portion is less than some threshold.


\rule{\linewidth}{0.2pt}

Originally tried 

The impedance of an antenna over frequency can be determined by:

\begin{itemize}
  \item Applying a gaussian pulse to a voltage source - in our case, applied to a via connecting the path (or probe)
  \item Running the simulation until the transients have all died out below some threshold, while logging the source voltage and current at each timestep
  \item Taking the fourier transform of the (real) excitation voltage and current (producing a complex result, mind you)
  \item Taking the ratio of the two complex spectra.
\end{itemize}

This is the computational equivalent of dropping a piano off a balcony to see which key is stuck.

See [Penney 1994], [Luebbers 1992], [Luebbers 1991], [Luk 1997]. 

Our implementation is in electronics/simple\_fdtd/runs/U.py.

A similar mismatch to the SPICE exists for fourier methods - but in the other direction.  The courant limit often demands fine timesteps, but since each FFT bin is $ f_{bin} = n_{bin} / (N_{simulation} \ dt) $ , the majority of the FFT bins exist into the hundreds or thousands of GHz, leaving no resolution in the low-frequency domain of interest unless $N_{simulation}$ is extremely large - even if all the transients in the simulation have died down, you still have to keep the sim running to make the FFT happy! 

There's more than enough 'information entropy' in 2000 FDTD points for most antennas. But you need some 30,000 points to get 10 bins below 20 GHz!

There are a few methods of changing the FFT bin size artificially, which [Bi 1992] reviews. You can "use a manual fourier integration over the frequency region of interest".

But, in a staggering turn of events which will presumably be familiar to statisticans and preposterous to everyone else, a far simpler method is to {\it discard} 95\% of the data, by down-sampling to 1/10th or so.

An equally simple method that seemed to produce better results in our case is to pad the voltage and current samples to the correct length. The jump discontinuity introduced by padding with zeros has a negligible effect.

It's so thumpingly unintuitive to me that adding 50,000 zeros to a 5000 value dataset can improve the resolution of a measurement by 300-fold.

It is important to remember to normalize the gaussian pulse, or else numerical noise will be introduced. The magnitude is not important - [Luebbers 1992] use 100v, others use 1v, etc.

Though uneven dt FFTs exist, the time step can be constant at the courant limit for this simulation.

A step impulse (1 first timestep, 0 otherwise) has been used in some works, though in our case performance was quite horrid.

A correction factor due to the staggered magnetic field of the Yee lattice must be introduced; [Fang 1994]. Their $Z_2$ equation (correcting for spatial inaccuracies, but not temporal) was sufficient.

A method of moments solver like NEC-2 may have provided faster results; but handling of multiple dielectrics does not seem to be simple.

This technique is equivalent to that used in electrochemistry, known as fourier impedance spectroscopy - except they seem to usually use a known impedance source rather than a hard source, presumably because ideal hard sources don't exist in reality.

Allowing the simulation to run for long enough that all transients dissipate is important for accuracy - deceptive dips in the current can cause early termination. A surprising amount of detail is contributed by even the smallest current levels. Our threshold is 1e-7 amps for 700 iterations.

[Samaras 2004] has a very useful set of experimental and FDTD data for calibration and comparison. Comparing a probe via source in the different positions, we obtained agreement of $\sim 7\%$ in impedance and $\sim 5\%$ in frequency.

The use of a hard source feed-port affects the number of timesteps required by introducing unphysical transients. Using a port with a virtual 50-ohm resistance reduces the computational requirements by a large factor; see [Luebbers 1996].

Simply monitoring the source current during the simulation is somewhat deceptive. Periodically monitoring the change in the fourier transform seems to be a better convergence metric.

The units of the FFT (unlike those of the continuous FT) remain in volts

\rule{\linewidth}{0.2pt}

Many equations in papers on the FDTD method are supplied without explicit scaling factors. For instance, for use with flaport/fdtd the H-field to current line integral in [] requires scaling by $\mu_0  (dx/dt)$, where $\mu_0$ is the vacuum magnetic permittivity, dx the cell size, and dt the timestep - despite the equation already possessing a deceptive set of $dx$-es.

Naturally, if one is competent, this discrepancy will be immediately obvious. Those not dimensionally-intuitive, such as myself, find it useful to run a test using a unit-aware calculator such as {\it sharkdp/insect}.

\rule{\linewidth}{0.2pt}

The impedance of a microstrip antenna varies with position on its plane. Probe feeds that couple a microstrip to a specific point are often used.

\rule{\linewidth}{0.2pt}


\label{para}
\ref{para}

\paragraph{Timeline}

\paragraph{Comments by others}

\paragraph{Lessons Learned} \


\rule{\linewidth}{0.2pt}

It may be helpful to think of simulations very similarly to IRL experiments. 

A simulation is just a universe in a bottle that you can examine more closely; as with real-world, you can learn much from observation, but 

But this need for documentation conflicts with the rapid, iterative cycle necessary for productivity.

This is obvious to all compentent, but when rapidly iteratively testing with simulations, it may be helpful to automatically save a package with images of all the components (schematics, graphs, input files) of each distinct test. 

For comparison to experiment, having a webcam take an image of the assembled board is also helpful. 

Version control alone isn't quite enough. Just having a simulation setup file somewhere in the commit history isn't "discoverable" - that is, you must be able to see what the input and output was without re-running the simulation. 

Manually taking notes tended to disrupt the flow of testing; and in any case, just noting "SIR filter has appropriate phase response" is almost useless. What {\it was} the phase response? Plot it!

Software such as Sumatra, Sacred, recipy, and others. In our case, we used eLabFTW's elabapy bindings.

\rule{\linewidth}{0.2pt}

It is far easier to use existing, well-characterized reference designs verbatim than to modify 

\rule{\linewidth}{0.2pt}

When rapidly testing data analyses which aren't really conducive to unit testing, I previously used to run the whole simulation, look at the analysis, re-run the sim, etc.

This is slow. I often don't change the input parameters for the sim, but just the analysis. However, there's often a large amount of state to persist to disk.

Saving the entire session with 'dill' is very helpful.

\rule{\linewidth}{0.2pt}

Software opacity is evil.

\rule{\linewidth}{0.2pt}

A great deal of time was spent trying to resolve version conflicts and dependency hells with the numerous libraries used by all the simulation programs. Over a week was spent trying to recursively track down all the This also wastes developer time - some fraction of issues raised are due to library version conflicts. 

Packaged binaries help this slightly, but of course don't help if modifications are required, and managing shared libraries is still a tricky matter.

Good solutions include OpenFOAM's Docker installation. In some cases, using chroot with the original developer's Linux distribution is also of some utility.

But this all seems like quite a lot of overhead and opacity for what ultimately doesn't seem a super-complex problem: deterministically obtain a known-good version of a library, build locally, and set paths appropriately.

A good example might be gTest's cmake integration.

In the extreme, systems exist to extract every 

In some situations (especially where the library has a permissive licence) perhaps it could be useful to consider packaging a complete, batteries-included 'known good' repository, either with the source of all the correct library versions included, or with a script to clone and compile the specific version used, integrating all the libraries with the build system. 

For instance, this was done with the PDB reader in the OpenMM wrapper and JAMES.

\rule{\linewidth}{0.2pt}

There's also a very neat thing that seems to be common in computational biology, but which doesn't seem popular in other fields. After an algorithm or software tool is written (and the source published seperately), a simple CGI frontend is written around it and hosted on the university's servers. eLNemo and the CHARMMing web interface are advanced examples of this. This way, anyone with an input file can get results without futzing around with installation. 

The computational biologists have beat us at our own game.

\rule{\linewidth}{0.2pt}


Write a paper to be understood; to be as clear and helpful as possible to the reader.

\rule{\linewidth}{0.2pt}

We have always encountered wasting extreme amounts of time on subtle assembly mistakes in hardware prototypes. 

In one example in this project, many hours were wasted because the enamel insulation on a bodge wire had not burned off completely in the solder joint, leading to a high-impedance connection.

The same has occurred in previous projects; in one example, many days were spent debugging software to fix an apparently slow hardware interrupt, which ended up being the result of a poor solder paste stencil leading to a hidden high-impedance connection to a leadless package.

Many failures are perhaps the result of carelessness in modification and a lack of inspection; but others would only have been found by a 100\% electrical test.

If flying-probe or bed-of-nails tests can be made sufficiently rapid and closely coupled with the existing toolchain, 

In {\it 2001: A space odyssey}, an automated system is shown guiding the troubleshooting of an assembly, apparently generating a fault tree of all the 

Boundary-scan features might really help 

\rule{\linewidth}{0.2pt}

The ability to almost immediately compare simulation to experiment was quite important.

\rule{\linewidth}{0.2pt}


\paragraph{Hall of Hubris} \

Lest our hats stop fitting

\rule{\linewidth}{0.2pt}

An inane remark:

\begin{displayquote}
We believe once we have the P. Syringae host, we from environmental samples
\end{displayquote}

Truly the depths of Dunning-Kruger.

\rule{\linewidth}{0.2pt}

An expert and distinguished gentleman that we contacted regarding assistance resolving transients in our microstrip VCO stated the following:



This was a perfectly sensible remark; it is almost always the case that (at X-band, no less!) a custom IC would have been needed to build a VCO.

Also, if taken in the context of a tired, overworked PI getting an unsolicited email from an excessively verbose undergraduate at a different university, I hardly think I would have replied differently.

However, I think this person may have missed out. Learning 

So perhaps it is wise to ponder the ideas of fools for skeet; one always learns target practice, if only an example what not to do, and occasionally one learns positively. I have often found that I learn greatly from working on the projects of others.

We present this only as a cautionary tale in the hopes that someday I will listen.

\rule{\linewidth}{0.2pt}

%\end{multicols}

\Acrobatmenu{GoBack}{Back}


\end{document}